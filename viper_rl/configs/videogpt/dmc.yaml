seed: 1234

batch_size: 32
lr: 1.e-4
total_steps: 800000
warmup_steps: 0
save_interval: 1000
test_interval: 10000
viz_interval: 10000
log_interval: 100
data_path: "viper_rl_data/datasets/dmc"

ema: 0.9999
optimizer: "adam"
lr_schedule: "constant"

image_size: 64
seq_len: 16
frame_skip: 1
ae_ckpt: "viper_rl_data/checkpoints/dmc_vqgan"

ae:
  image_size: 64
  ch: 128
  ch_mult: [1, 2, 2, 2]
  num_res_blocks: 1
  attn_resolutions: []
  z_channels: 64
  double_z: false
  dropout: 0.
  n_embed: 256
  embed_dim: 64
  patch_size: [8, 8]

n_classes: 17
class_cond: true

model: "videogpt"
transformer:
  embed_dim: 256
  num_heads: 8
  num_layers: 8
  mlp_dim: 1024
  dropout: 0.1
  attention_dropout: 0.1

open_loop_ctx: 1
